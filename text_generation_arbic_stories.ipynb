{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mnto026Zkj0M"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import os \n",
    "import time\n",
    "import re\n",
    "\n",
    "# NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0OOSai7XtnwO"
   },
   "outputs": [],
   "source": [
    "# read the data  \n",
    "text=open('qisasse_com.txt','rb').read().decode(encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2vFJvJs8FUP9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return \"\".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FfMOHfltF82B"
   },
   "outputs": [],
   "source": [
    "text=preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WnC13xjvoCFN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'قصة الملك وابنة الخادمة\\nأراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلامه  فتسارعت الفتيات لحضور الحفل\\nكان هناك\\nكان هناك ملك أراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلامه  فتسارعت الفتيات '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZCB5JlzhuzvT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 unique characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'A',\n",
       " 'E',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'K',\n",
       " 'M',\n",
       " 'N',\n",
       " 'S',\n",
       " 'T',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'إ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ـ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ى',\n",
       " 'ي',\n",
       " '٠',\n",
       " '١',\n",
       " '٢',\n",
       " '٣',\n",
       " '٤',\n",
       " '٥',\n",
       " '٩',\n",
       " 'ٹ',\n",
       " 'پ',\n",
       " 'ک',\n",
       " 'ں',\n",
       " 'ھ',\n",
       " 'ہ',\n",
       " 'ۃ',\n",
       " 'ی',\n",
       " 'ې',\n",
       " 'ﺀ',\n",
       " 'ﺁ',\n",
       " 'ﺃ',\n",
       " 'ﺄ',\n",
       " 'ﺇ',\n",
       " 'ﺈ',\n",
       " 'ﺌ',\n",
       " 'ﺍ',\n",
       " 'ﺎ',\n",
       " 'ﺏ',\n",
       " 'ﺐ',\n",
       " 'ﺑ',\n",
       " 'ﺒ',\n",
       " 'ﺓ',\n",
       " 'ﺔ',\n",
       " 'ﺕ',\n",
       " 'ﺖ',\n",
       " 'ﺗ',\n",
       " 'ﺘ',\n",
       " 'ﺛ',\n",
       " 'ﺜ',\n",
       " 'ﺝ',\n",
       " 'ﺟ',\n",
       " 'ﺠ',\n",
       " 'ﺡ',\n",
       " 'ﺢ',\n",
       " 'ﺣ',\n",
       " 'ﺤ',\n",
       " 'ﺧ',\n",
       " 'ﺨ',\n",
       " 'ﺩ',\n",
       " 'ﺪ',\n",
       " 'ﺫ',\n",
       " 'ﺬ',\n",
       " 'ﺭ',\n",
       " 'ﺮ',\n",
       " 'ﺯ',\n",
       " 'ﺰ',\n",
       " 'ﺱ',\n",
       " 'ﺲ',\n",
       " 'ﺳ',\n",
       " 'ﺴ',\n",
       " 'ﺷ',\n",
       " 'ﺸ',\n",
       " 'ﺻ',\n",
       " 'ﺼ',\n",
       " 'ﺽ',\n",
       " 'ﺿ',\n",
       " 'ﻀ',\n",
       " 'ﻂ',\n",
       " 'ﻃ',\n",
       " 'ﻄ',\n",
       " 'ﻆ',\n",
       " 'ﻇ',\n",
       " 'ﻈ',\n",
       " 'ﻊ',\n",
       " 'ﻋ',\n",
       " 'ﻌ',\n",
       " 'ﻍ',\n",
       " 'ﻏ',\n",
       " 'ﻐ',\n",
       " 'ﻒ',\n",
       " 'ﻓ',\n",
       " 'ﻔ',\n",
       " 'ﻗ',\n",
       " 'ﻘ',\n",
       " 'ﻙ',\n",
       " 'ﻚ',\n",
       " 'ﻛ',\n",
       " 'ﻜ',\n",
       " 'ﻝ',\n",
       " 'ﻞ',\n",
       " 'ﻟ',\n",
       " 'ﻠ',\n",
       " 'ﻡ',\n",
       " 'ﻢ',\n",
       " 'ﻣ',\n",
       " 'ﻤ',\n",
       " 'ﻥ',\n",
       " 'ﻦ',\n",
       " 'ﻧ',\n",
       " 'ﻨ',\n",
       " 'ﻩ',\n",
       " 'ﻪ',\n",
       " 'ﻫ',\n",
       " 'ﻬ',\n",
       " 'ﻭ',\n",
       " 'ﻮ',\n",
       " 'ﻯ',\n",
       " 'ﻰ',\n",
       " 'ﻱ',\n",
       " 'ﻲ',\n",
       " 'ﻳ',\n",
       " 'ﻴ',\n",
       " 'ﻷ',\n",
       " 'ﻹ',\n",
       " 'ﻻ',\n",
       " 'ﻼ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the unique characters in the file \n",
    "vocab=sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vTULk00rx045"
   },
   "outputs": [],
   "source": [
    "# The i:j part of the comprehension creates a new key-value pair in the dictionary, with the key being the element j and the value being the index i.\n",
    "char_idx={j:i for i,j in enumerate(vocab)}\n",
    "idx_char=np.array(vocab)\n",
    "text_as_int=np.array([char_idx[c] for c in text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CNQvJitGMHKS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11,\n",
       " 'A': 12,\n",
       " 'E': 13,\n",
       " 'G': 14,\n",
       " 'H': 15,\n",
       " 'I': 16,\n",
       " 'K': 17,\n",
       " 'M': 18,\n",
       " 'N': 19,\n",
       " 'S': 20,\n",
       " 'T': 21,\n",
       " '_': 22,\n",
       " 'a': 23,\n",
       " 'b': 24,\n",
       " 'c': 25,\n",
       " 'd': 26,\n",
       " 'e': 27,\n",
       " 'f': 28,\n",
       " 'g': 29,\n",
       " 'h': 30,\n",
       " 'i': 31,\n",
       " 'k': 32,\n",
       " 'l': 33,\n",
       " 'm': 34,\n",
       " 'n': 35,\n",
       " 'o': 36,\n",
       " 'p': 37,\n",
       " 'q': 38,\n",
       " 'r': 39,\n",
       " 's': 40,\n",
       " 't': 41,\n",
       " 'u': 42,\n",
       " 'v': 43,\n",
       " 'w': 44,\n",
       " 'x': 45,\n",
       " 'y': 46,\n",
       " 'z': 47,\n",
       " 'ء': 48,\n",
       " 'آ': 49,\n",
       " 'أ': 50,\n",
       " 'ؤ': 51,\n",
       " 'إ': 52,\n",
       " 'ئ': 53,\n",
       " 'ا': 54,\n",
       " 'ب': 55,\n",
       " 'ة': 56,\n",
       " 'ت': 57,\n",
       " 'ث': 58,\n",
       " 'ج': 59,\n",
       " 'ح': 60,\n",
       " 'خ': 61,\n",
       " 'د': 62,\n",
       " 'ذ': 63,\n",
       " 'ر': 64,\n",
       " 'ز': 65,\n",
       " 'س': 66,\n",
       " 'ش': 67,\n",
       " 'ص': 68,\n",
       " 'ض': 69,\n",
       " 'ط': 70,\n",
       " 'ظ': 71,\n",
       " 'ع': 72,\n",
       " 'غ': 73,\n",
       " 'ـ': 74,\n",
       " 'ف': 75,\n",
       " 'ق': 76,\n",
       " 'ك': 77,\n",
       " 'ل': 78,\n",
       " 'م': 79,\n",
       " 'ن': 80,\n",
       " 'ه': 81,\n",
       " 'و': 82,\n",
       " 'ى': 83,\n",
       " 'ي': 84,\n",
       " '٠': 85,\n",
       " '١': 86,\n",
       " '٢': 87,\n",
       " '٣': 88,\n",
       " '٤': 89,\n",
       " '٥': 90,\n",
       " '٩': 91,\n",
       " 'ٹ': 92,\n",
       " 'پ': 93,\n",
       " 'ک': 94,\n",
       " 'ں': 95,\n",
       " 'ھ': 96,\n",
       " 'ہ': 97,\n",
       " 'ۃ': 98,\n",
       " 'ی': 99,\n",
       " 'ې': 100,\n",
       " 'ﺀ': 101,\n",
       " 'ﺁ': 102,\n",
       " 'ﺃ': 103,\n",
       " 'ﺄ': 104,\n",
       " 'ﺇ': 105,\n",
       " 'ﺈ': 106,\n",
       " 'ﺌ': 107,\n",
       " 'ﺍ': 108,\n",
       " 'ﺎ': 109,\n",
       " 'ﺏ': 110,\n",
       " 'ﺐ': 111,\n",
       " 'ﺑ': 112,\n",
       " 'ﺒ': 113,\n",
       " 'ﺓ': 114,\n",
       " 'ﺔ': 115,\n",
       " 'ﺕ': 116,\n",
       " 'ﺖ': 117,\n",
       " 'ﺗ': 118,\n",
       " 'ﺘ': 119,\n",
       " 'ﺛ': 120,\n",
       " 'ﺜ': 121,\n",
       " 'ﺝ': 122,\n",
       " 'ﺟ': 123,\n",
       " 'ﺠ': 124,\n",
       " 'ﺡ': 125,\n",
       " 'ﺢ': 126,\n",
       " 'ﺣ': 127,\n",
       " 'ﺤ': 128,\n",
       " 'ﺧ': 129,\n",
       " 'ﺨ': 130,\n",
       " 'ﺩ': 131,\n",
       " 'ﺪ': 132,\n",
       " 'ﺫ': 133,\n",
       " 'ﺬ': 134,\n",
       " 'ﺭ': 135,\n",
       " 'ﺮ': 136,\n",
       " 'ﺯ': 137,\n",
       " 'ﺰ': 138,\n",
       " 'ﺱ': 139,\n",
       " 'ﺲ': 140,\n",
       " 'ﺳ': 141,\n",
       " 'ﺴ': 142,\n",
       " 'ﺷ': 143,\n",
       " 'ﺸ': 144,\n",
       " 'ﺻ': 145,\n",
       " 'ﺼ': 146,\n",
       " 'ﺽ': 147,\n",
       " 'ﺿ': 148,\n",
       " 'ﻀ': 149,\n",
       " 'ﻂ': 150,\n",
       " 'ﻃ': 151,\n",
       " 'ﻄ': 152,\n",
       " 'ﻆ': 153,\n",
       " 'ﻇ': 154,\n",
       " 'ﻈ': 155,\n",
       " 'ﻊ': 156,\n",
       " 'ﻋ': 157,\n",
       " 'ﻌ': 158,\n",
       " 'ﻍ': 159,\n",
       " 'ﻏ': 160,\n",
       " 'ﻐ': 161,\n",
       " 'ﻒ': 162,\n",
       " 'ﻓ': 163,\n",
       " 'ﻔ': 164,\n",
       " 'ﻗ': 165,\n",
       " 'ﻘ': 166,\n",
       " 'ﻙ': 167,\n",
       " 'ﻚ': 168,\n",
       " 'ﻛ': 169,\n",
       " 'ﻜ': 170,\n",
       " 'ﻝ': 171,\n",
       " 'ﻞ': 172,\n",
       " 'ﻟ': 173,\n",
       " 'ﻠ': 174,\n",
       " 'ﻡ': 175,\n",
       " 'ﻢ': 176,\n",
       " 'ﻣ': 177,\n",
       " 'ﻤ': 178,\n",
       " 'ﻥ': 179,\n",
       " 'ﻦ': 180,\n",
       " 'ﻧ': 181,\n",
       " 'ﻨ': 182,\n",
       " 'ﻩ': 183,\n",
       " 'ﻪ': 184,\n",
       " 'ﻫ': 185,\n",
       " 'ﻬ': 186,\n",
       " 'ﻭ': 187,\n",
       " 'ﻮ': 188,\n",
       " 'ﻯ': 189,\n",
       " 'ﻰ': 190,\n",
       " 'ﻱ': 191,\n",
       " 'ﻲ': 192,\n",
       " 'ﻳ': 193,\n",
       " 'ﻴ': 194,\n",
       " 'ﻷ': 195,\n",
       " 'ﻹ': 196,\n",
       " 'ﻻ': 197,\n",
       " 'ﻼ': 198}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "60pvFK1iyM35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76, 68, 56,  1, 54, 78, 79, 78, 77,  1, 82, 54, 55, 80, 56,  1, 54,\n",
       "       78, 61, 54, 62, 79, 56,  0, 50, 64, 54, 62,  1, 50, 80,  1, 84, 57,\n",
       "       65, 82, 59,  1,  1, 75, 76, 64, 64,  1, 50, 80,  1, 84, 76, 84, 79,\n",
       "        1, 60, 75, 78, 54,  1, 84, 59, 79, 72,  1, 75, 84, 81,  1, 55, 80,\n",
       "       54, 57,  1, 54, 78, 76, 64, 84, 56,  1, 78, 84, 61, 57, 54, 64,  1,\n",
       "       79, 80, 81, 80,  1, 75, 64, 84, 66, 56,  1, 54, 60, 78, 54, 79, 81,\n",
       "        1,  1, 75, 57, 66, 54, 64, 72, 57,  1, 54, 78, 75, 57, 84, 54, 57,\n",
       "        1, 78, 60, 69, 82, 64,  1, 54, 78, 60, 75, 78,  0, 77, 54, 80,  1,\n",
       "       81, 80, 54, 77,  0, 77, 54, 80,  1, 81, 80, 54, 77,  1, 79, 78, 77,\n",
       "        1, 50, 64, 54, 62,  1, 50, 80,  1, 84, 57, 65, 82, 59,  1,  1, 75,\n",
       "       76, 64, 64,  1, 50, 80,  1, 84, 76, 84, 79,  1, 60, 75, 78, 54,  1,\n",
       "       84, 59, 79, 72,  1, 75, 84, 81,  1, 55, 80, 54, 57,  1, 54, 78, 76,\n",
       "       64, 84, 56,  1, 78, 84, 61, 57, 54, 64,  1, 79, 80, 81, 80,  1, 75,\n",
       "       64, 84, 66, 56,  1, 54, 60, 78, 54, 79, 81,  1,  1, 75, 57, 66, 54,\n",
       "       64, 72, 57,  1, 54, 78, 75, 57, 84, 54, 57,  1, 78, 60, 69, 82, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int[:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kPjGzofayN5q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'قصة الملك واب'--------- characters mapped to int--------> [76 68 56  1 54 78 79 78 77  1 82 54 55]\n"
     ]
    }
   ],
   "source": [
    "# show ho the first 20 chararacters from the text are mapped to integers\n",
    "print('{}--------- characters mapped to int--------> {}'.format(repr(text[:13]),text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X0sptO9ELmeS"
   },
   "outputs": [],
   "source": [
    "# the maximum lenght sentence for the single input in characters\n",
    "seq_length=100\n",
    "# create training exaples / targets\n",
    "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1x_Qj5ZBNUeb"
   },
   "outputs": [],
   "source": [
    "# to make the input the same size in the character  and add the one character to make the  traget \n",
    "squences=char_dataset.batch(seq_length+1,drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYFBfao7ychc"
   },
   "source": [
    "function returns a printable representation of the given object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zksK64yHxgqj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'قصة الملك وابنة الخادمة\\nأراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلام' tf.Tensor(\n",
      "[76 68 56  1 54 78 79 78 77  1 82 54 55 80 56  1 54 78 61 54 62 79 56  0\n",
      " 50 64 54 62  1 50 80  1 84 57 65 82 59  1  1 75 76 64 64  1 50 80  1 84\n",
      " 76 84 79  1 60 75 78 54  1 84 59 79 72  1 75 84 81  1 55 80 54 57  1 54\n",
      " 78 76 64 84 56  1 78 84 61 57 54 64  1 79 80 81 80  1 75 64 84 66 56  1\n",
      " 54 60 78 54 79], shape=(101,), dtype=int32) 101\n",
      "'ه  فتسارعت الفتيات لحضور الحفل\\nكان هناك\\nكان هناك ملك أراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات ا' tf.Tensor(\n",
      "[81  1  1 75 57 66 54 64 72 57  1 54 78 75 57 84 54 57  1 78 60 69 82 64\n",
      "  1 54 78 60 75 78  0 77 54 80  1 81 80 54 77  0 77 54 80  1 81 80 54 77\n",
      "  1 79 78 77  1 50 64 54 62  1 50 80  1 84 57 65 82 59  1  1 75 76 64 64\n",
      "  1 50 80  1 84 76 84 79  1 60 75 78 54  1 84 59 79 72  1 75 84 81  1 55\n",
      " 80 54 57  1 54], shape=(101,), dtype=int32) 101\n",
      "'لقرية ليختار منهن فريسة احلامه  فتسارعت الفتيات لحضور الحفل\\nكان هناك ملك أراد أن يتزوج  فقرر أن يقيم ' tf.Tensor(\n",
      "[78 76 64 84 56  1 78 84 61 57 54 64  1 79 80 81 80  1 75 64 84 66 56  1\n",
      " 54 60 78 54 79 81  1  1 75 57 66 54 64 72 57  1 54 78 75 57 84 54 57  1\n",
      " 78 60 69 82 64  1 54 78 60 75 78  0 77 54 80  1 81 80 54 77  1 79 78 77\n",
      "  1 50 64 54 62  1 50 80  1 84 57 65 82 59  1  1 75 76 64 64  1 50 80  1\n",
      " 84 76 84 79  1], shape=(101,), dtype=int32) 101\n",
      "'حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلامه  فتسارعت الفتيات لحضور الحفل \\nوكان هناك فتاة فقيرة' tf.Tensor(\n",
      "[60 75 78 54  1 84 59 79 72  1 75 84 81  1 55 80 54 57  1 54 78 76 64 84\n",
      " 56  1 78 84 61 57 54 64  1 79 80 81 80  1 75 64 84 66 56  1 54 60 78 54\n",
      " 79 81  1  1 75 57 66 54 64 72 57  1 54 78 75 57 84 54 57  1 78 60 69 82\n",
      " 64  1 54 78 60 75 78  1  0 82 77 54 80  1 81 80 54 77  1 75 57 54 56  1\n",
      " 75 76 84 64 56], shape=(101,), dtype=int32) 101\n",
      "' ابنة خادمة بسيطة  وقد تعلقت هذه الفتاة بذاك الملك وتمنت أن تكون هي زوجته المستقبلية\\nفقررت أن تذهب لل' tf.Tensor(\n",
      "[ 1 54 55 80 56  1 61 54 62 79 56  1 55 66 84 70 56  1  1 82 76 62  1 57\n",
      " 72 78 76 57  1 81 63 81  1 54 78 75 57 54 56  1 55 63 54 77  1 54 78 79\n",
      " 78 77  1 82 57 79 80 57  1 50 80  1 57 77 82 80  1 81 84  1 65 82 59 57\n",
      " 81  1 54 78 79 66 57 76 55 78 84 56  0 75 76 64 64 57  1 50 80  1 57 63\n",
      " 81 55  1 78 78], shape=(101,), dtype=int32) 101\n"
     ]
    }
   ],
   "source": [
    "for item in squences.take(5):\n",
    "  print(repr(''.join(idx_char[item.numpy()])),item,len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6mhXA1g-xmZ5"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text=chunk[:-1]\n",
    "    traget_text=chunk[1:]\n",
    "    return input_text,traget_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ahUKDLiAzmHV"
   },
   "outputs": [],
   "source": [
    "dataset=squences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3Uh1gbzp0h6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data  قصة الملك وابنة الخادمة\n",
      "أراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلا\n",
      "Taraget data  صة الملك وابنة الخادمة\n",
      "أراد أن يتزوج  فقرر أن يقيم حفلا يجمع فيه بنات القرية ليختار منهن فريسة احلام\n"
     ]
    }
   ],
   "source": [
    "for i ,j in dataset.take(1):\n",
    "    print('input data','',''.join(idx_char[i.numpy()]))\n",
    "    print('Taraget data','',''.join(idx_char[j.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AfqsY1hd1mBN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15155"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "htEhXpgD3U4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=64\n",
    "BUFFER_SIZE=10000\n",
    "# make the  dataset shuffle  and put in the batch\n",
    "dataset=dataset.shuffle(BUFFER_SIZE).batch(batch_size,drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q2PN1UIG3wwU"
   },
   "outputs": [],
   "source": [
    "vocb_size=len(vocab)\n",
    "embedding_dim=256\n",
    "ruu_units=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HK1VKpk47Ak9"
   },
   "outputs": [],
   "source": [
    "def build_model(vocb_size,embedding_dim,ruu_units,batch_size):\n",
    "    model=tf.keras.Sequential([\n",
    "      tf.keras.layers.Embedding(vocb_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
    "      tf.keras.layers.GRU(ruu_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
    "      tf.keras.layers.Dense(vocb_size)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UiVRvGZFJ7rI"
   },
   "outputs": [],
   "source": [
    "Model=build_model(vocb_size=len(vocab),embedding_dim=embedding_dim,ruu_units=ruu_units,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wT46ovXb9z1o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           50944     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 199)           203975    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,193,223\n",
      "Trainable params: 4,193,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7pQOVvERWFAh"
   },
   "outputs": [],
   "source": [
    "# Use this crossentropy loss function when there are two or more label classes.\n",
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Kic6427B-HiB"
   },
   "outputs": [],
   "source": [
    "Model.compile(optimizer = 'adam',loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NLNaqyn-Qsm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  9/236 [>.............................] - ETA: 11:14 - loss: 4.8915"
     ]
    }
   ],
   "source": [
    "history=Model.fit(dataset,epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
